{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7m1yIKWyYLYn"
      },
      "source": [
        "## Creative Optimization Tutorial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JqXeMvoYLYw"
      },
      "source": [
        "### What resources do we have"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbqtTFs8YLYx"
      },
      "source": [
        "Resources:\n",
        "- Creative URL\n",
        "- Assets\n",
        "- Performance Score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nF-ZZMgYLYy"
      },
      "source": [
        "#### Where to Begin ??"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8ee1vOjYLYy"
      },
      "source": [
        "- Need to find a way to represent a creative or parts of it\n",
        "  - Extracting:\n",
        "    - Start Frame and\n",
        "    - End Frame\n",
        "  - Extracting the entire creative as a video"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "747He3NKYLYz"
      },
      "source": [
        "#### Extracting Start Frame and End Frame or Preview Video of a Creative"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Gmg4rWpYLY0"
      },
      "source": [
        "> We can use Selenium to Load the creative on a automated browser follow its progression and capture screenshots at certain moments or Record the entire creative."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zBfgDQrMYLY1"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "from typing import Tuple\n",
        "from time import sleep\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
        "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
        "from os import path\n",
        "from subprocess import Popen, call\n",
        "import subprocess\n",
        "import pyautogui\n",
        "import ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from selenium import webdriver\n",
        "# from webdriver_manager.chrome import ChromeDriverManager\n",
        "\n",
        "# # driver = webdriver.Chrome(ChromeDriverManager().install())\n",
        "# driver = webdriver.Chrome('C:/chromedriver.exe');\n",
        "\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "\n",
        "# driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
        "# driver.get(\"https://www.google.com\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mX4TUR3wYLY3"
      },
      "outputs": [],
      "source": [
        "class CreativeFrameExtractor:\n",
        "    '''\n",
        "    Class responsible for Extracting Creative Start and End Frames.\n",
        "    It requires a chrome webdriver compatible with selenium to be\n",
        "    installed/included in the run environment path.\n",
        "    '''\n",
        "\n",
        "    def __init__(self, preview_url: str, \n",
        "                 engagement_type: str, \n",
        "                 save_location: str = '',\n",
        "                 browser_edges: Tuple[float, float] = (70, 1039)) -> None:\n",
        "        \n",
        "        self.preview_url = preview_url\n",
        "        self.engagement_type = engagement_type\n",
        "        self.browser_edges = browser_edges\n",
        "        self.file_name = '-'.join(preview_url.split('/')[-3:-1])\n",
        "        self.save_location = save_location\n",
        "        self.video_name = path.join(self.save_location, self.file_name)\n",
        "        print(self.video_name)\n",
        "        print(self.file_name)\n",
        "        print(self.save_location)\n",
        "        self.cmd = f\"ffmpeg -f gdigrab -draw_mouse 0 -framerate 60 -i desktop -vcodec libx264rgb {self.video_name}.mp4 -y\"\n",
        "        # self.cmd = f\"ffmpeg -f gdigrab -offset_x 1600 -offset_y 0 -video_size 1600x1200 -draw_mouse 0 -framerate 60 -i desktop -vcodec libx264rgb {self.video_name}.mp4\"\n",
        "        \n",
        "        # Configurations\n",
        "\n",
        "        # Browser Configuration\n",
        "        # Browser Options\n",
        "        self.opt = Options()\n",
        "        self.opt.add_argument(\"--hide-scrollbars\")\n",
        "        self.opt.add_experimental_option(\n",
        "            \"excludeSwitches\", [\"enable-automation\"])\n",
        "        # Browser Logs\n",
        "        self.capabilities = DesiredCapabilities.CHROME\n",
        "        self.capabilities[\"goog:loggingPrefs\"] = {\"browser\": \"ALL\"}\n",
        "\n",
        "    def is_status_complete(self, passed_driver) -> bool:\n",
        "        '''\n",
        "        Function to check status of the AD-Unit and its completion.\n",
        "        '''\n",
        "        # Retrieve logs from browser\n",
        "        logs = passed_driver.get_log(\"browser\")\n",
        "\n",
        "        for log in logs:\n",
        "            # Select logs coming from AD-Unit\n",
        "            if log[\"source\"] == \"console-api\":\n",
        "                # Extract message from log\n",
        "                message = log[\"message\"]\n",
        "\n",
        "                if '\"GAME CREATED\"' in message or '\"DROPPED\"' in message:\n",
        "                    # Start Recording Game\n",
        "                    print(\"Starting Recording AD-UNIT...\")\n",
        "                    print(log)\n",
        "                    return False\n",
        "\n",
        "                if '\"START\"' in message:\n",
        "                    # Engaged\n",
        "                    print(\"AD-UNIT Engaged...\")\n",
        "                    print(log)\n",
        "                    return False\n",
        "\n",
        "                if '\"GAME COMPLETE\"' in message:\n",
        "                    # Stop Recording Game\n",
        "                    print(\"Stopped Recording AD-UNIT...\")\n",
        "                    print(log)\n",
        "                    return True\n",
        "\n",
        "        return False\n",
        "    \n",
        "    @staticmethod\n",
        "    def terminate(process):\n",
        "        '''\n",
        "        Function to stop/terminate a process.\n",
        "        '''\n",
        "        # Video Recording Process Terminator\n",
        "        if process.poll() is None:\n",
        "            call(\"taskkill /F /T /PID \" + str(process.pid))\n",
        "\n",
        "    @staticmethod\n",
        "    def crop_video(filename: str, x_pos: float = 0, y_pos: float = 70, width: float = 650, height: float = 970) -> None:\n",
        "        '''\n",
        "        Function to crop a video with given location and size specific parameters.\n",
        "        '''\n",
        "        print(filename)\n",
        "        input_video = ffmpeg.input(f\"{filename}.mp4\")\n",
        "        cropped_video = ffmpeg.crop(input_video, x_pos, y_pos, width, height)\n",
        "        output_video = ffmpeg.output(cropped_video, f\"{filename}_cropped.mp4\")\n",
        "        ffmpeg.run(output_video)\n",
        "\n",
        "    def _imitate_engagement(self, ad_size: Tuple[float, float]) -> None:\n",
        "        '''\n",
        "        Function to imitate a given engagement type.\n",
        "        '''\n",
        "        center = (ad_size[0]/2, self.browser_edges[0] + (ad_size[1]/2))\n",
        "\n",
        "        if self.engagement_type == \"tap\":\n",
        "            pyautogui.moveTo(center[0], center[1], duration=1)\n",
        "            pyautogui.leftClick()\n",
        "\n",
        "        elif self.engagement_type == \"swipe right\":\n",
        "            pyautogui.moveTo(center[0], center[1], duration=1)\n",
        "            pyautogui.dragRel(center[0], 0, duration=1)\n",
        "\n",
        "        elif self.engagement_type == \"swipe left\":\n",
        "            pyautogui.moveTo(center[0], center[1], duration=1)\n",
        "            pyautogui.dragRel(-center[0], 0, duration=1)\n",
        "\n",
        "        elif self.engagement_type == \"tap and hold\":\n",
        "            pyautogui.moveTo(center[0], center[1], duration=1)\n",
        "            pyautogui.click()\n",
        "\n",
        "        elif self.engagement_type == \"scrub\":\n",
        "            pyautogui.moveTo(center[0] - (1/2 * center[0]),\n",
        "                             center[1] - (2/3 * center[1]), duration=0.2)\n",
        "            pyautogui.dragRel(center[0], 0, duration=0.2)\n",
        "            pyautogui.dragRel(-center[0], (1/3 * center[1]), duration=0.2)\n",
        "            pyautogui.dragRel(center[0], 0, duration=0.2)\n",
        "            pyautogui.dragRel(-center[0], (1/3 * center[1]), duration=0.2)\n",
        "            pyautogui.dragRel(center[0], 0, duration=0.2)\n",
        "            \n",
        "    def generate_preview_video(self) -> None:\n",
        "        '''\n",
        "        Function to generate preview video and also a cropped version of the video.\n",
        "        '''\n",
        "        # Initialize Selenium WebDriver\n",
        "\n",
        "        # driver = webdriver.Chrome(\n",
        "        #     options=self.opt, desired_capabilities=self.capabilities)\n",
        "        driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
        "\n",
        "        # Maximize WebDriver's Window to Maximum Size\n",
        "        driver.maximize_window()\n",
        "\n",
        "        try:\n",
        "\n",
        "            # Load AD-Unit through Selenium\n",
        "            driver.get(self.preview_url)\n",
        "\n",
        "            # Locate AD-Unit Element from Browser\n",
        "            canvas = driver.find_element(By.TAG_NAME, \"canvas\")\n",
        "            \n",
        "            # # Start Recording Entire Screen\n",
        "            # video_recording = Popen(self.cmd)\n",
        "            video_recording = subprocess.Popen(self.cmd,shell=True,stdout=subprocess.PIPE,stderr=subprocess.STDOUT)\n",
        "\n",
        "\n",
        "            # # Identify Size of AD-Unit\n",
        "            ad_size = (canvas.size.get(\"width\"), canvas.size.get(\"height\"))\n",
        "\n",
        "            # Engage Ad-Unit\n",
        "            self._imitate_engagement(ad_size)\n",
        "\n",
        "            # Continuously Check Status of AD-Unit using its console logs\n",
        "            # until it reached a \"GAME COMPLETE\" Status\n",
        "            WebDriverWait(driver, 100).until(self.is_status_complete)\n",
        "\n",
        "            sleep(5)\n",
        "\n",
        "            # Stop Video Recording\n",
        "            self.terminate(video_recording)\n",
        "\n",
        "            # Close Selenium Browser Window\n",
        "            driver.close()\n",
        "\n",
        "            # Crop Generated Preview Video Recording\n",
        "            # self.crop_video(self.video_name, x_pos=0, y_pos=70,width=ad_size[0], height=ad_size[1])\n",
        "            print(self.video_name)\n",
        "            self.crop_video('./extracted_images/video', x_pos=0, y_pos=70,width=ad_size[0], height=ad_size[1])\n",
        "\n",
        "        except TimeoutException:\n",
        "            print(\"TimeOut Exception Fired\")\n",
        "            print(\"AD-Unit Status Console Logs did not Complete. Engagement Failed.\")\n",
        "            driver.close()\n",
        "\n",
        "        except NoSuchElementException:\n",
        "            print(f\"AD-Unit Failed to Load: {self.preview_url}\")\n",
        "            driver.close()\n",
        "\n",
        "    def generate_frames(self) -> None:\n",
        "        '''\n",
        "        Function to generate creative start and end frames.\n",
        "        '''\n",
        "        # Initialize Selenium WebDriver\n",
        "        # driver = webdriver.Chrome(\n",
        "        #     options=self.opt, desired_capabilities=self.capabilities, )\n",
        "        driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
        "\n",
        "        # Maximize WebDriver's Window to Maximum Size\n",
        "        driver.maximize_window()\n",
        "\n",
        "        try:\n",
        "            # Load AD-Unit through Selenium\n",
        "            driver.get(self.preview_url)\n",
        "\n",
        "            # Locate AD-Unit Element from Browser\n",
        "            canvas = driver.find_element(By.TAG_NAME, \"canvas\")\n",
        "\n",
        "            # Capture Start Frame\n",
        "            canvas.screenshot(\n",
        "                path.join(self.save_location, f'{self.file_name}_start_frame.png'))\n",
        "            print('Start Frame captured')\n",
        "\n",
        "            # Identify Size of AD-Unit\n",
        "            ad_size = (canvas.size.get(\"width\"), canvas.size.get(\"height\"))\n",
        "\n",
        "            # Engage Ad-Unit\n",
        "            self._imitate_engagement(ad_size)\n",
        "\n",
        "            # Continuously Check Status of AD-Unit using its console logs\n",
        "            # until it reached a \"GAME COMPLETE\" Status\n",
        "            WebDriverWait(driver, 100).until(self.is_status_complete)\n",
        "\n",
        "            sleep(5)\n",
        "\n",
        "            # Capture End Frame\n",
        "            canvas.screenshot(path.join(self.save_location,f'{self.file_name}_end_frame.png'))\n",
        "            print('End Frame Captured')\n",
        "\n",
        "            # Close Selenium Browser Window\n",
        "            driver.close()\n",
        "\n",
        "        except TimeoutException:\n",
        "            print(\"TimeOut Exception Fired\")\n",
        "            print(\"AD-Unit Status Console Logs did not Complete. Engagement Failed.\")\n",
        "            driver.close()\n",
        "\n",
        "        except NoSuchElementException:\n",
        "            print(f\"AD-Unit Failed to Load: {self.preview_url}\")\n",
        "            driver.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dRV0yBwuYLY9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "./extracted_images/5a48ffcbf611f167ecbb884e807f31f6-7e6dcb347f24c7843a8d\n",
            "5a48ffcbf611f167ecbb884e807f31f6-7e6dcb347f24c7843a8d\n",
            "./extracted_images/\n"
          ]
        }
      ],
      "source": [
        "# Creating Extractor Object\n",
        "ext = CreativeFrameExtractor(\n",
        "    'https://s3.us-east-1.amazonaws.com/a.futureadlabs.com-us-east-1-backup/us-east-1/games/5a48ffcbf611f167ecbb884e807f31f6/7e6dcb347f24c7843a8d/index.html', 'tap', save_location='./extracted_images/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2Ww6mjMCYLY_",
        "outputId": "2fc7a66a-678a-40d7-836f-f8c9be566a0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start Frame captured\n",
            "Starting Recording AD-UNIT...\n",
            "{'level': 'INFO', 'message': 'https://s3.us-east-1.amazonaws.com/a.futureadlabs.com-us-east-1-backup/us-east-1/games/5a48ffcbf611f167ecbb884e807f31f6/7e6dcb347f24c7843a8d/index.html 19:16 \"GAME CREATED\"', 'source': 'console-api', 'timestamp': 1667529029909}\n",
            "Stopped Recording AD-UNIT...\n",
            "{'level': 'INFO', 'message': 'https://s3.us-east-1.amazonaws.com/a.futureadlabs.com-us-east-1-backup/us-east-1/games/5a48ffcbf611f167ecbb884e807f31f6/7e6dcb347f24c7843a8d/index.html 22:16 \"GAME COMPLETE\"', 'source': 'console-api', 'timestamp': 1667529047825}\n",
            "End Frame Captured\n"
          ]
        }
      ],
      "source": [
        "# Calling Generate Frames from Extractor Object\n",
        "ext.generate_frames()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "MrzjSyynYLZB",
        "outputId": "c5bf3502-bdf6-434a-9517-2c54ce3e677e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting Recording AD-UNIT...\n",
            "{'level': 'INFO', 'message': 'https://s3.us-east-1.amazonaws.com/a.futureadlabs.com-us-east-1-backup/us-east-1/games/5a48ffcbf611f167ecbb884e807f31f6/7e6dcb347f24c7843a8d/index.html 19:16 \"GAME CREATED\"', 'source': 'console-api', 'timestamp': 1667529060479}\n",
            "Stopped Recording AD-UNIT...\n",
            "{'level': 'INFO', 'message': 'https://s3.us-east-1.amazonaws.com/a.futureadlabs.com-us-east-1-backup/us-east-1/games/5a48ffcbf611f167ecbb884e807f31f6/7e6dcb347f24c7843a8d/index.html 22:16 \"GAME COMPLETE\"', 'source': 'console-api', 'timestamp': 1667529078033}\n",
            "./extracted_images/5a48ffcbf611f167ecbb884e807f31f6-7e6dcb347f24c7843a8d\n",
            "./extracted_images/video\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "module 'ffmpeg' has no attribute 'input'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10168\\901565574.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Calling Generate Preview Video from Extractor Object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_preview_video\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10168\\1467382929.py\u001b[0m in \u001b[0;36mgenerate_preview_video\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    166\u001b[0m             \u001b[1;31m# self.crop_video(self.video_name, x_pos=0, y_pos=70,width=ad_size[0], height=ad_size[1])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvideo_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcrop_video\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./extracted_images/video'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_pos\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pos\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m70\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mad_size\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mad_size\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTimeoutException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10168\\1467382929.py\u001b[0m in \u001b[0;36mcrop_video\u001b[1;34m(filename, x_pos, y_pos, width, height)\u001b[0m\n\u001b[0;32m     83\u001b[0m         '''\n\u001b[0;32m     84\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m         \u001b[0minput_video\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mffmpeg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{filename}.mp4\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m         \u001b[0mcropped_video\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mffmpeg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_video\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_pos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[0moutput_video\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mffmpeg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcropped_video\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf\"{filename}_cropped.mp4\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mAttributeError\u001b[0m: module 'ffmpeg' has no attribute 'input'"
          ]
        }
      ],
      "source": [
        "# Calling Generate Preview Video from Extractor Object\n",
        "ext.generate_preview_video()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQtfj0j0YLZC"
      },
      "source": [
        "#### Extracting Colors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ObMRcFjVYLZC"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'extcolors'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16968\\1631415586.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mextcolors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcolormap\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrgb2hex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'extcolors'"
          ]
        }
      ],
      "source": [
        "import extcolors\n",
        "import pandas as pd\n",
        "from colormap import rgb2hex\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axvX-bfDYLZD"
      },
      "outputs": [],
      "source": [
        "def identify_color_composition(image,\n",
        "                               tolerance: int = 12,\n",
        "                               limit: int = 1,\n",
        "                               visualize: bool = False) -> None:\n",
        "    \"\"\"Function that identifies the color composition of a\n",
        "    given image path.\"\"\"\n",
        "\n",
        "    extracted_colors = extcolors.extract_from_path(\n",
        "        image, tolerance=tolerance, limit=limit)\n",
        "\n",
        "    identified_colors = color_to_df(extracted_colors)\n",
        "\n",
        "    if not visualize:\n",
        "        return identified_colors\n",
        "\n",
        "    list_color = list(identified_colors['c_code'])\n",
        "    list_percent = [int(i) for i in list(identified_colors['occurrence'])]\n",
        "\n",
        "    text_c = [c + ' ' + str(round(p*100/sum(list_percent), 1)) + '%' for c, p in zip(list_color,\n",
        "                                                                                     list_percent)]\n",
        "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(100, 100), dpi=10)\n",
        "    wedges, _ = ax[0].pie(list_percent,\n",
        "                          labels=text_c,\n",
        "                          labeldistance=1.05,\n",
        "                          colors=list_color,\n",
        "                          textprops={'fontsize': 60, 'color': 'black'}\n",
        "                          )\n",
        "\n",
        "    plt.setp(wedges, width=0.3)\n",
        "\n",
        "    # create space in the center\n",
        "    plt.setp(wedges, width=0.36)\n",
        "\n",
        "    ax[0].set_aspect(\"equal\")\n",
        "    fig.set_facecolor('grey')\n",
        "\n",
        "    ax[1].imshow(Image.open(image))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    return identified_colors\n",
        "\n",
        "\n",
        "def color_to_df(extracted_colors: tuple):\n",
        "    \"\"\"Converts RGB Color values from extcolors output to HEX Values.\"\"\"\n",
        "\n",
        "    colors_pre_list = str(extracted_colors).replace(\n",
        "        '([(', '').replace(')],', '), (').split(', (')[0:-1]\n",
        "    df_rgb = [i.split('), ')[0] + ')' for i in colors_pre_list]\n",
        "    df_percent = [i.split('), ')[1].replace(')', '')\n",
        "                  for i in colors_pre_list]\n",
        "\n",
        "    # convert RGB to HEX code\n",
        "    df_rgb_values = [(int(i.split(\", \")[0].replace(\"(\", \"\")),\n",
        "                      int(i.split(\", \")[1]),\n",
        "                      int(i.split(\", \")[2].replace(\")\", \"\"))) for i in df_rgb]\n",
        "\n",
        "    df_color_up = [rgb2hex(int(i.split(\", \")[0].replace(\"(\", \"\")),\n",
        "                           int(i.split(\", \")[1]),\n",
        "                           int(i.split(\", \")[2].replace(\")\", \"\"))) for i in df_rgb]\n",
        "\n",
        "    colors_df = pd.DataFrame(zip(df_color_up, df_rgb_values, df_percent),\n",
        "                             columns=['c_code', 'rgb', 'occurrence'])\n",
        "\n",
        "    return colors_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ajwcyDQYLZD",
        "outputId": "4ce7a811-9333-4ba6-9acb-a52b3c0f4b3e"
      },
      "outputs": [],
      "source": [
        "identify_color_composition('./extracted_images/5a48ffcbf611f167ecbb884e807f31f6-7e6dcb347f24c7843a8d_start_frame.png',tolerance=100,limit=8, visualize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ak15dTyMYLZE",
        "outputId": "d0eb7586-926e-4b81-decf-a68216880e6a"
      },
      "outputs": [],
      "source": [
        "identify_color_composition(\n",
        "    './Challenge_Data/Assets/5a48ffcbf611f167ecbb884e807f31f6/engagement_instruction.png', visualize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2pg53BrYLZE",
        "outputId": "abf81232-835e-4641-f56a-7fa4f5433662"
      },
      "outputs": [],
      "source": [
        "identify_color_composition(\n",
        "    './Challenge_Data/Assets/5a48ffcbf611f167ecbb884e807f31f6/cta.png', limit=3 ,visualize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DD0x8_qAYLZF"
      },
      "source": [
        "> What features can be Extracted from Color ?\n",
        "- Number of Colors used\n",
        "- Background Color\n",
        "- Text Color\n",
        "- Contrast, Saturation, ...\n",
        "- and more ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZOL3KBWYLZF"
      },
      "source": [
        "#### Extracting Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-X8fkxKYLZG"
      },
      "outputs": [],
      "source": [
        "import pytesseract\n",
        "import cv2\n",
        "import numpy as np\n",
        "from typing import List, Tuple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4YXHAM8yYLZG"
      },
      "outputs": [],
      "source": [
        "def convert_hex_to_rgb(hex_color: str, normalize: bool = True) -> List[str]:\n",
        "    \"\"\"Converts a HEX color to a RGB color\n",
        "\n",
        "    Args:\n",
        "        hex_color (str): HEX color code to convert\n",
        "        normalize (bool, optional): Choice to normalize calculated rgb values . Defaults to True.\n",
        "\n",
        "    Returns:\n",
        "        List[str]: List of RGB values in order, normalized or not.\n",
        "    \"\"\"\n",
        "    colors = hex_color[1:]\n",
        "\n",
        "    # Convert HEX color values to RGB Values\n",
        "    colors = [int(colors[0:2], base=16),  # RED\n",
        "              int(colors[2:4], base=16),  # GREEN\n",
        "              int(colors[4:6], base=16)]  # BLUE\n",
        "\n",
        "    # Normalize RGB values\n",
        "    if normalize:\n",
        "        colors = [color / 255 for color in colors]\n",
        "\n",
        "    return colors\n",
        "\n",
        "def get_luminance(hex_color: str) -> float:\n",
        "    \"\"\"Calculates the luminance of a given HEX color\n",
        "\n",
        "    Args:\n",
        "        hex_color (str): HEX color code to calculate luminance for\n",
        "\n",
        "    Returns:\n",
        "        float: luminance value of color\n",
        "    \"\"\"\n",
        "    colors = convert_hex_to_rgb(hex_color)\n",
        "\n",
        "    luminance = colors[0] * 0.2126 + colors[1] * 0.7152 + colors[2] * 0.0722\n",
        "\n",
        "    return luminance\n",
        "\n",
        "def fix_image_background(image_path: str):\n",
        "    identified_colors = identify_color_composition(image_path)\n",
        "    text_color = identified_colors['c_code'].to_list()[0]\n",
        "    text_color_rgb = identified_colors['rgb'].to_list()[0]\n",
        "    luminance = get_luminance(hex_color=text_color)\n",
        "\n",
        "    if luminance < 140:\n",
        "        background_color = (255, 255, 255)\n",
        "    else:\n",
        "        background_color = (0, 0, 0)\n",
        "\n",
        "    # Load image\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Make all perfectly green pixels white\n",
        "    image[np.all(image != text_color_rgb, axis=-1)] = background_color\n",
        "\n",
        "    return image\n",
        "\n",
        "def extract_text(image_path, tesseract_cmd: str, fix_background: bool = False):\n",
        "    pytesseract.pytesseract.tesseract_cmd = tesseract_cmd\n",
        "    try:\n",
        "        if fix_background:\n",
        "            text = pytesseract.image_to_string(\n",
        "                fix_image_background(image_path))\n",
        "        else:\n",
        "            text = pytesseract.image_to_string(image_path)\n",
        "\n",
        "        return text\n",
        "\n",
        "    except pytesseract.TesseractNotFoundError:\n",
        "        raise Exception(\n",
        "            f'Failure: Tesseract is not installed or not available in the defined path {tesseract_cmd}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_XW9MFlTYLZH",
        "outputId": "b043cd17-3947-4f5d-db7f-d701759ff6f3"
      },
      "outputs": [],
      "source": [
        "extract_text('./extracted_images/5a48ffcbf611f167ecbb884e807f31f6-7e6dcb347f24c7843a8d_start_frame.png',\n",
        "             r'C:\\Program Files\\Tesseract-OCR\\tesseract')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9tjq24s8YLZH",
        "outputId": "a6002442-5efc-439a-fa26-e3da65301c28"
      },
      "outputs": [],
      "source": [
        "extract_text('./Challenge_Data/Assets/5a48ffcbf611f167ecbb884e807f31f6/engagement_instruction.png',\n",
        "             r'C:\\Program Files\\Tesseract-OCR\\tesseract', fix_background=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-FJm_TfYLZH",
        "outputId": "ffea7ca5-5fff-4d88-99de-5eca3b99b1c1"
      },
      "outputs": [],
      "source": [
        "extract_text('./Challenge_Data/Assets/5a48ffcbf611f167ecbb884e807f31f6/cta.png',\n",
        "             r'C:\\Program Files\\Tesseract-OCR\\tesseract', fix_background=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpkl_IaIYLZI"
      },
      "source": [
        "> What features can be Extracted from Text ?\n",
        "- Number of Characters\n",
        "- Number of Words\n",
        "- ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvX6KteYYLZI"
      },
      "source": [
        "#### Locating Assets within Creative"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwbtHaEWYLZI"
      },
      "outputs": [],
      "source": [
        "def locate_image_on_image(locate_image: str, on_image: str, prefix: str = '', visualize: bool = False, color: Tuple[int, int, int] = (0, 0, 255)):\n",
        "    try:\n",
        "\n",
        "        image = cv2.imread(on_image)\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "        template = cv2.imread(locate_image, 0)\n",
        "\n",
        "        result = cv2.matchTemplate(gray, template, cv2.TM_CCOEFF)\n",
        "        _, _, _, max_loc = cv2.minMaxLoc(result)\n",
        "\n",
        "        height, width = template.shape[:2]\n",
        "\n",
        "        top_left = max_loc\n",
        "        bottom_right = (top_left[0] + width, top_left[1] + height)\n",
        "\n",
        "        if visualize:\n",
        "            cv2.rectangle(image, top_left, bottom_right, color, 1)\n",
        "            plt.figure(figsize=(10, 10))\n",
        "            plt.axis('off')\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "            plt.imshow(image)\n",
        "\n",
        "        return {f'{prefix}top_left_pos': top_left, f'{prefix}bottom_right_pos': bottom_right}\n",
        "\n",
        "    except cv2.error as err:\n",
        "        print(err)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ZNURwpLYLZJ",
        "outputId": "8ca1e9f4-a35b-4217-9a01-7423c84fe5be"
      },
      "outputs": [],
      "source": [
        "locate_image_on_image(\n",
        "    './Challenge_Data/Assets/4c3bb41d4f40f39842b7b8d3f536366a/engagement_instruction.png', './Challenge_Data/Assets/4c3bb41d4f40f39842b7b8d3f536366a/_preview.png', prefix='eng_', visualize=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcJvZXP-YLZJ",
        "outputId": "95c811e5-02cb-4a7f-c79a-ace5c8ff0202"
      },
      "outputs": [],
      "source": [
        "locate_image_on_image(\n",
        "    './Challenge_Data/Assets/fef95c5e1ee5bc235b56d7c508d3bcd0/engagement_instruction.png', './Challenge_Data/Assets/fef95c5e1ee5bc235b56d7c508d3bcd0/_preview.png', prefix='eng_', visualize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxYzw_DMYLZK"
      },
      "source": [
        "> What features can be Extracted from Locating Assets ?\n",
        "- Size\n",
        "- Ratio\n",
        "- Total Covered Area\n",
        "- and more ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAdZwCY6YLZK"
      },
      "source": [
        "#### Object Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8-0dUKRYLZK"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVmARcCVYLZL",
        "outputId": "a7e91320-7c94-4ed1-bb94-5bf2259c05f9"
      },
      "outputs": [],
      "source": [
        "%cd yolov7\n",
        "! python detect.py --weights yolov7-tiny.pt --conf 0.4 --img-size 1280 --source ../extracted_images/5a48ffcbf611f167ecbb884e807f31f6-7e6dcb347f24c7843a8d_start_frame.png --project trial --name run\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMmvJZ-GYLZL"
      },
      "source": [
        "> What features can be Extracted from Object Detection ?\n",
        "- Object Detected\n",
        "- Number of Objects Detected\n",
        "- and more ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Te-g_wT7YLZM"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.7.13 ('py37')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "0d4a887298c93e75dfac186fa3dbba4a0d244ea35d4e1c173dcb1dd3c776512e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
